---
title: "Statistik"
author: "CH.4 - Zweidimensionale Verteilungen"
date: "`r format(Sys.time(), '%Y')` || Prof. Dr. Buchwitz, Sommer, Henke"

toc: true
tocoverview: false
tocheader: Inhaltsübersicht
titlefontsize: 22pt

output: fhswf::presentation
knit: rmarkdown::render
---

```{r setup, include=FALSE}
library(knitr)
options(digits = 4)
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, cache=TRUE, 
                      dev.args=list(pointsize=11), size="scriptsize")

# Packages
library(car)
library(fGarch)
library(gtools)
library(HistogramTools)
library(ineq)
library(kableExtra)
library(texreg)
library(tidyverse)
library(vcd)
```

## Lernziele

- Erweiterung der Streuungsbetrachtung von einem auf zwei Merkmale
- Erkennen des Zusammenhangs von Streuung mehrerer Variablen und (linearem) Zusammenhang
- Diskussion und Betrachtung relevanter MAßzahlen zur Messung von Zusammenhängen

# Streuung und Streudiagramme

## Rekapitulation: Streuung

\kariert{18}

## Zweidimensionale Verteilungen

**Ausgangspunkt:**

- Jede statistische Einheit einer Grundgesamtheit trägt eine Vielzahl von Merkmalen.
- In diesem Kapitel werden zwei Merkmale gleichzeitig untersucht.
- Bei der Darstellung und Analyse von Abhängigkeiten zwischen Variablen muss das Skalenniveau berücksichtigt werden.

**Beispiel:**

- Studierende
  + Beispiel: Körpergröße und Gewicht $\rightarrow$ Streudiagramm
  + Beispiel: Geschlecht und Studiengang $\rightarrow$ Kontingenztafel
- Kraftfahrzeuge
  + Beispiel: Höchstgeschwindigkeit und Motorleistung
  + Beispiel: Kraftstoffverbrauch und Getriebeart (Manuell/Automatik)

## Beispiel: Streudiagramm

::: {.columns}
::: {.column width=30%}
```{r, echo=F,size="tiny"}
height <- c(1.63,1.51,1.56,1.95,1.8,1.79,1.78,1.68,1.89,1.61,1.89,1.97,1.61,
            1.57,1.83,1.8,1.72,1.52,1.54)
weight <- c(68,81,72,128,60,64,94,62,109,75,76,126,98,71,66,111,89,76,45)

hw <- data.frame(height, weight)
kable(hw, col.names=c("Größe (m)","Gewicht (kg)"))

```
**R-Befehl:** `plot()`
:::
::: {.column width=70%}
```{r, echo=F, fig.width=5}
plot(x=height, y=weight, pch=19, main="Zusammenhang zwischen \n Größe und Gewicht",
     ylab="Gewicht in kg", xlab="Größe in m", ylim=c(0, 140), xlim=c(1.2, 2.2))
```
:::
:::


# Kovarianz 

## Kovarianz

```{r, echo=F}
set.seed(1)


height <- runif(35,150,200) # Experience
weight <- 25 + 1.5* height + rnorm(length(height), sd=4)
plot(weight, height, xlab="Gewicht in kg (X)", ylab="Körpergröße in cm (Y)",
     main="Gewicht (kg) vs. Körpergröße (cm)", xaxt="n", yaxt="n")
abline(h = mean(height), col="red")
abline(v = mean(weight), col="red")
axis(1,at=mean(weight), labels=expression(bar(x)), col="red", col.axis="red")
axis(2,at=mean(height), labels=expression(bar(y)), col="red", col.axis="red")
```

## Kovarianz

**Aufgabe: Bestimmen des Vorzeichens**

- $y_i - \bar{y}$ ist die Differenz jeder Beobachtung $y_i$ vom arithmetischen Mittel der abhängigen Variablen
- $x_i - \bar{x}$ ist die Abweichung $x_i$ vom arithmetischen Mittel des Prädiktors
- $(y_i - \bar{y})(x_i - \bar{x})$ ist das Produkt der vorherigen beiden Größen

```{r, echo=F}
quandrant <- c("1 (oben rechts)","2 (oben links)","3 (unten links)", "4 (unten rechts)")
df <- data.frame(quandrant, x="", y="", z="")
cnames <- c("Quadrant","$y_i -\\bar{y}$","$x_i - \\bar{x}$","$(y_i - \\bar{y})(x_i - \\bar{x})$")
knitr::kable(df, booktabs=T, col.names = cnames, align = c("l","c","c","c"), escape=F) %>%
  kable_styling(position = "center")
```


## Kovarianz

### Positiver Zusammenhang
- Wenn der Zusammenhang zwischen $Y$ und $X$ **positiv** ist (also wenn $X$ größer wird, dann wird auch $Y$ größer), dann sind mehr Datenpunkte im ersten und dritten Quadranten als im zweiten und vierten.
- Die Summe der Elemente in der letzten Spalte der vorherigen Tabelle ist dann mit großer Wahrscheinlichkeit positiv, also $Cov(Y,X) > 0$.

\pause

### Negativer Zusammenhang
- Wenn der lineare Zusammenhang zwischen $Y$ und $X$ **negativ** ist (z.B. wenn $X$ sinkt, steigt $Y$), dann befinden sich mehr Datenpunkte im zweiten und vierten Quadranten als im ersten und dritten.
- Die Summe der Elemente in der letzten Spalte der vorherigen Tabelle ist dann mit großer Wahrscheinlichkeit negativ, also $Cov(Y,X) < 0$.

## Kovarianz

$$ s_{XY} = Cov(X,Y) = \frac{1}{n-1} \sum_{i=1}^{n} (y_i - \bar{y})(x_i - \bar{x})$$

- Die oben stehende Formeln gibt die Kovarianz zwischen $X$ und $Y$ an.
- Das Vorzeichen der Kovarianz ist ein Indikator für die Richtung eines bestehenden **linearen** Zusammenhangs zwischen $Y$ und $X$.
- Die Kovarianz erlaubt es nicht, Aussagen über die Stärke eines Zusammenhangs zu treffen.
- Die Größe der Kovarianz ist abhängig von der zugrundeliegenden Einheit. Einheitenwechsel (z.B. von Euro zu TEuro) führen zu einer Wertveränderung.
- **R-Befehl:** `cov()`

# Korrelation

## Korrelationskoeffizient

$$ Cor(Y,X) = \frac{1}{n-1}\sum_{i=1}^{n} (\frac{y_i - \bar{y}}{s_y})(\frac{x_i - \bar{x}}{s_x}) = \frac{Cov(Y,X)}{s_ys_x} = \frac{s_{XY}}{s_x \cdot s_y}$$

- Der Korrelationskoeffizient ist ein Maß für die Stärke des linearen Zusammenhangs.
- Im Unterschied zur Kovarianz ist $Cor(Y,X)$ nicht skalenabhängig und erlaubt die Einschätzung von Stärke und Richtung eines linearen Zusammenhangs. 
- **R-Befehl:** `cor()`

\begin{alertblock}{}\Large
$Cor(Y,X) = 0$ bedeutet nicht, dass es zwischen $X$ und $Y$ keinen Zusammenhang gibt.
\end{alertblock}

## Eigenschaften

1. Wertebereich: $-1 \leq r_{XY} \leq 1$
2. Ist $r_{XY} = 0$, so sind $X$ und $Y$ nicht korreliert (unkorreliert).
3. Ist $r_{XY} > 0$, so sind $X$ und $Y$ gleichläufig (gleichsinnig) korreliert.
4. Ist $r_{XY} < 0$, so sind $X$ und $Y$ gegenläufig (ungleichsinnig) korreliert.
5. Je größer $|r_{XY}|$ ist, desto stärker ist die Korrelation zwischen $X$ and $Y$.

## Scheinkorrelation

**Scheinkorrelation:** obwohl ein großer Wert des Korrelationskoeffizienten zwischen $X$ und $Y$ besteht, liegt kein *ursächlicher* (und/oder sachlogischer) Zusammenhang zwischen $X$ und $Y$ vor. 

### Beispiel
Zusammenhang zwischen Kindergeburten und der Anzahl der Storchenpaare, die sich in einer Region ansiedeln.

## Scheinkorrelation

```{r, echo=F, fig.height=4.5}
# Suicides by hangig, strangulation and suffocation (count)
x <-c(5427, 5688, 6198, 6462, 6635, 7336, 7248, 7491, 8161, 8578, 9000)
# US Spending on science, space, and technology (bn dollars)
y <- c(18.079, 18.594, 19.753, 20.734, 20.831, 23.029, 23.597, 23.584, 25.525, 27.731, 29.449)
# Time
t <- 1999:2009
plot(t,y, ylim=c(15,30), type="b", ylab="", xlab="", 
     main="US Spending on science, space, and technology and \n Suicides by hangig, strangulation and suffocation")
mtext(paste("korrelation:",signif(cor(x,y),digits=4)))
par(new=T)
plot(t, x, type = "b", axes = FALSE, bty = "n", xlab = "", ylab = "", col="red")
axis(side=4, at = pretty(range(x)), col="red", col.axis="red")
```

\tiny
- Weitere Beispiele unter: http://tylervigen.com/spurious-correlations

## Verständnisfragen

- Welche Darstellungsmöglichkeiten gibt es für zweidimensionale Daten?
- Bedeutet ein Korrelationskoeffizient nah bei 1, dass ein sachlicher Zusammenhang zwischen den untersuchten Merkmalen besteht?
- Wie ist ein Korrelationskoeffizient nah bei -1 zu interpretieren?

